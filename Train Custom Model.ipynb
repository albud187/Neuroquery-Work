{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "from scipy import sparse\n",
    "import pandas as pd\n",
    "from joblib import Memory\n",
    "from nilearn import plotting\n",
    "\n",
    "from neuroquery import datasets\n",
    "from neuroquery.img_utils import coordinates_to_maps\n",
    "from neuroquery.smoothed_regression import SmoothedRegression\n",
    "from neuroquery.tokenization import TextVectorizer\n",
    "from neuroquery.encoding import NeuroQueryModel\n",
    "cache_directory = \"cache\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "CORPUS_FILE = \"autism_data.csv\"\n",
    "#VOCAB_FILE = \"vocabulary.csv\"\n",
    "CORPUS_FILE_MASTER = \"corpus_metadata.csv\"\n",
    "\n",
    "data_dir = pathlib.Path(datasets.fetch_neuroquery_model())\n",
    "\n",
    "corpus_metadata = pd.read_csv(CORPUS_FILE)\n",
    "corpus_masterdata = pd.read_csv(CORPUS_FILE_MASTER)\n",
    "# vectorizer = TextVectorizer.from_vocabulary_file(\n",
    "#     str(VOCAB_FILE)\n",
    "# )\n",
    "\n",
    "vectorizer = TextVectorizer.from_vocabulary_file(\n",
    "    str(data_dir / \"vocabulary.csv\")\n",
    ")\n",
    "\n",
    "# The TFIDF features stored with NeuroQuery data correspond to the terms in\n",
    "# `vocabulary.csv` and the studies in `corpus_metadata.csv`;\n",
    "# see `README.md` in the data directory for details\n",
    "tfidf = sparse.load_npz(str(data_dir / \"corpus_tfidf.npz\"))\n",
    "\n",
    "coordinates = pd.read_csv(datasets.fetch_peak_coordinates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "[Memory] Calling neuroquery.img_utils.coordinates_to_maps...\n",
      "coordinates_to_maps(            pmid table_id table_name     x     y     z\n",
      "0       26160289    t0010    Table 2  -3.0  42.0  12.0\n",
      "1       26160289    t0010    Table 2  -3.0 -57.0  23.0\n",
      "2       26160289    t0010    Table 2   4.0 -57.0  24.0\n",
      "3       26160289    t0010    Table 2  -9.0  54.0  27.0\n",
      "4       27535906       T1   Table 1.  15.0  36.0  22.0\n",
      "...          ...      ...        ...   ...   ...   ...\n",
      "469255  18559106       T2    Table 2 -26.0 -32.0  46.0\n",
      "469256  18559106       T3    Table 3 -22.0  16.0  21.0\n",
      "469257  18559106       T3    Table 3  24.0   9.0  23.0\n",
      "469258  18559106       T3    Table 3 -39.0 -48.0  27.0\n",
      "469259  18559106       T3    Table 3  38.0 -46.0  25.0\n",
      "\n",
      "[469260 rows x 6 columns], target_affine=(6, 6, 6), fwhm=9.0)\n",
      "Transforming 469260 coordinates for 13459 articles\n",
      "100.0% pmid:  28928708           \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-28-1ba2ee8de3b9>:10: UserWarning: Persisting input arguments took 2.46s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  brain_maps, masker = coord_to_maps(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________coordinates_to_maps - 3601.6s, 60.0min\n"
     ]
    }
   ],
   "source": [
    "# We cache the `coordinates_to_maps` function with joblib to avoid recomputing\n",
    "# this if we train a new model.\n",
    "coord_to_maps = Memory(cache_directory).cache(coordinates_to_maps)\n",
    "\n",
    "# You can set target_affine to a different value to increase image resolution\n",
    "# or reduce computation time. The model on neuroquery.org uses 4 mm\n",
    "# resolution i.e. target_affine=(4, 4, 4)\n",
    "# You can also adjust the smoothing by setting `fwhm` (Full Width at Half\n",
    "# maximum)\n",
    "brain_maps, masker = coord_to_maps(\n",
    "    coordinates, target_affine=(6, 6, 6), fwhm=9.0\n",
    ")\n",
    "brain_maps = brain_maps[(brain_maps.values != 0).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pmids_list = list(corpus_masterdata['pmid'])\n",
    "autism_pmids_list = list(corpus_metadata['pmid'])\n",
    "kept_studies =[]\n",
    "for study in all_pmids_list:\n",
    "    if study not in autism_pmids_list:\n",
    "        kept_studies.append(False)\n",
    "    else:\n",
    "        kept_studies.append(True)\n",
    "\n",
    "kept_idx = pd.Series(kept_studies) \n",
    "\n",
    "\n",
    "pmids = brain_maps.index.intersection(corpus_metadata[\"pmid\"])\n",
    "# kept_idx = corpus_metadata[\"pmid\"].isin(pmids)\n",
    "tfidf = tfidf.A[kept_idx, :]\n",
    "brain_maps = brain_maps.loc[pmids, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting smoothed regression model on 30 samples...\n",
      "keeping 115 features\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SmoothedRegression(alphas=[1.0, 10.0, 100.0])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor = SmoothedRegression(alphas=[1.0, 10.0, 100.0])\n",
    "\n",
    "print(\n",
    "    \"Fitting smoothed regression model on {} samples...\".format(tfidf.shape[0])\n",
    ")\n",
    "regressor.fit(tfidf, brain_maps.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_directory = \"autism_model\"\n",
    "\n",
    "corpus_metadata = corpus_metadata.set_index(\"pmid\").loc[pmids, :].reset_index()\n",
    "encoder = NeuroQueryModel(\n",
    "    vectorizer,\n",
    "    regressor,\n",
    "    masker.mask_img_,\n",
    "    corpus_info={\n",
    "        \"tfidf\": sparse.csr_matrix(tfidf),\n",
    "        \"metadata\": corpus_metadata,\n",
    "    },\n",
    ")\n",
    "encoder.to_data_dir(output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding \"Autism\"\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Size of label 'j' for operand 1 (6289) does not match previous terms (6308).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\neuroquery\\smoothed_regression.py\u001b[0m in \u001b[0;36mtransform_to_brain_maps\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform_to_z_maps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\neuroquery\\smoothed_regression.py\u001b[0m in \u001b[0;36mtransform_to_z_maps\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtransform_to_z_maps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msmoothing_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregression_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform_to_z_maps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\neuroquery\\nmf.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     63\u001b[0m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m         s = np.einsum(\n\u001b[0m\u001b[0;32m     65\u001b[0m             \u001b[1;34m\"ij,jk,lk\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalized_V_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mV_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36meinsum\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\einsumfunc.py\u001b[0m in \u001b[0;36meinsum\u001b[1;34m(*operands, **kwargs)\u001b[0m\n\u001b[0;32m   1377\u001b[0m     \u001b[1;31m# Build the contraction list and operand\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1378\u001b[1;33m     operands, contraction_list = einsum_path(*operands, optimize=optimize_arg,\n\u001b[0m\u001b[0;32m   1379\u001b[0m                                              einsum_call=True)\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36meinsum_path\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\einsumfunc.py\u001b[0m in \u001b[0;36meinsum_path\u001b[1;34m(*operands, **kwargs)\u001b[0m\n\u001b[0;32m    881\u001b[0m                 \u001b[1;32melif\u001b[0m \u001b[0mdim\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdimension_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mchar\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 882\u001b[1;33m                     raise ValueError(\"Size of label '%s' for operand %d (%d) \"\n\u001b[0m\u001b[0;32m    883\u001b[0m                                      \u001b[1;34m\"does not match previous terms (%d).\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Size of label 'j' for operand 1 (6289) does not match previous terms (6308).",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-ecc8fda5914a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Encoding \"{}\"'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mplotting\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview_img\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"brain_map\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen_in_browser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\neuroquery\\encoding.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, document)\u001b[0m\n\u001b[0;32m    242\u001b[0m         \"\"\"\n\u001b[0;32m    243\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeep_pos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 244\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdocument\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    245\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m         similar_words = pd.DataFrame(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\neuroquery\\encoding.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, documents)\u001b[0m\n\u001b[0;32m    199\u001b[0m         \u001b[0mraw_tfidf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_tfidf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msmoothed_regression\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregression_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintercept_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m         brain_maps = self.smoothed_regression.transform_to_brain_maps(\n\u001b[0m\u001b[0;32m    202\u001b[0m             \u001b[0mraw_tfidf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m         )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\neuroquery\\smoothed_regression.py\u001b[0m in \u001b[0;36mtransform_to_brain_maps\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     74\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform_to_z_maps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\neuroquery\\smoothed_regression.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msmoothing_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregression_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\neuroquery\\nmf.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m         s = np.einsum(\n\u001b[0m\u001b[0;32m     65\u001b[0m             \u001b[1;34m\"ij,jk,lk\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalized_V_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mV_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m         )\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36meinsum\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\einsumfunc.py\u001b[0m in \u001b[0;36meinsum\u001b[1;34m(*operands, **kwargs)\u001b[0m\n\u001b[0;32m   1376\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1377\u001b[0m     \u001b[1;31m# Build the contraction list and operand\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1378\u001b[1;33m     operands, contraction_list = einsum_path(*operands, optimize=optimize_arg,\n\u001b[0m\u001b[0;32m   1379\u001b[0m                                              einsum_call=True)\n\u001b[0;32m   1380\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36meinsum_path\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\einsumfunc.py\u001b[0m in \u001b[0;36meinsum_path\u001b[1;34m(*operands, **kwargs)\u001b[0m\n\u001b[0;32m    880\u001b[0m                     \u001b[0mdimension_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mchar\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    881\u001b[0m                 \u001b[1;32melif\u001b[0m \u001b[0mdim\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdimension_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mchar\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 882\u001b[1;33m                     raise ValueError(\"Size of label '%s' for operand %d (%d) \"\n\u001b[0m\u001b[0;32m    883\u001b[0m                                      \u001b[1;34m\"does not match previous terms (%d).\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m                                      % (char, tnum, dimension_dict[char], dim))\n",
      "\u001b[1;31mValueError\u001b[0m: Size of label 'j' for operand 1 (6289) does not match previous terms (6308)."
     ]
    }
   ],
   "source": [
    "query = \"Autism\"\n",
    "print('Encoding \"{}\"'.format(query))\n",
    "\n",
    "result = encoder(query)\n",
    "\n",
    "plotting.view_img(result[\"brain_map\"], threshold=3.0).open_in_browser()\n",
    "\n",
    "print(\"Similar words:\")\n",
    "print(result[\"similar_words\"].head())\n",
    "print(\"\\nSimilar documents:\")\n",
    "print(result[\"similar_documents\"].head())\n",
    "\n",
    "print(\"\\nmodel saved in {}\".format(output_directory))\n",
    "\n",
    "# Display in notebook\n",
    "plotting.view_img(result[\"brain_map\"], threshold=3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 6308)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
